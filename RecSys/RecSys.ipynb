{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install cufflinks==0.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os\n",
    "import re, json\n",
    "import pickle, gzip\n",
    "import itertools\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "import boto3\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "import cufflinks as cf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import  Image\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# plotly + cufflinks work offline\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'slalom-ml'\n",
    "prefix = 'tmp/sagemaker/demo/recsys/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Movie Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "%cd ml-100k\n",
    "#!shuf ua.base -o ua.base.shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!cat README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Data and Exploratory Data Analysis\n",
    "\n",
    "We observe the ratings are not in a matrix format, but are in a _long and skinny_ format.  We'll need to build the matrix ourselves.\n",
    "\n",
    "We also observe there is a user dataset in **u.user**, providing some infor about gender, occupation, and zipcode. And information about the movie itself: title, release date, URL, and category in the **u.item** file.  Lastly, I think about how I've rated movies; I'm curious if there is any skew to the ratings themselves.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_column_names = ['user_id', 'age', 'gender', 'occupation', 'zip code']\n",
    "film_column_names = ['film_id', 'title', 'release date', 'home release date', 'URL', 'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Noir','Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "data_column_names = ['user_id', 'film_id', 'rating', 'timestamp']\n",
    "user_df = pd.read_csv('u.user', sep='|', names=user_column_names)\n",
    "film_df = pd.read_csv('u.item', sep='|', names=film_column_names, encoding = \"ISO-8859-1\")\n",
    "\n",
    "ua_data = pd.read_csv('ua.base', sep='\\t', names=data_column_names).drop(['timestamp'], axis=1)\n",
    "ua_test = pd.read_csv('ua.test', sep='\\t', names=data_column_names).drop(['timestamp'], axis=1)\n",
    "\n",
    "data_df = ua_data\n",
    "test_df = ua_test\n",
    "print('\\nDESCRIPTION of Ratings data\\n')\n",
    "print(data_df.describe())\n",
    "\n",
    "print('\\n\\nSAMPLE of UA Training (ratings)  data\\n')\n",
    "print(data_df.sample(n=5))\n",
    "\n",
    "print('\\n\\nSAMPLE of UA Testing (ratings) data\\n')\n",
    "print(test_df.sample(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data_df.user_id.max()\n",
    "films = data_df.film_id.max()\n",
    "\n",
    "data = [\n",
    "    go.Bar(x=['users'],  y=[users], name=\"Users\"),\n",
    "    go.Bar(x=['films'],  y=[films], name=\"Films\")\n",
    "]\n",
    "layout = dict(yaxis=dict(title='Count') )\n",
    "figure = dict(data=data, layout=layout)\n",
    "py.iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "Is there a lot of skew in our data?  What does the rating distribution look like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.groupby('rating').count()['film_id'].iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "rgba(255, 153, 51, 0.6)",
          "line": {
           "color": "rgba(255, 153, 51, 1.0)",
           "width": 1
          }
         },
         "name": "None",
         "orientation": "v",
         "text": "",
         "type": "bar",
         "x": [
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          79,
          80,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          155,
          156,
          157,
          158,
          161,
          162,
          163,
          164,
          165,
          167,
          169,
          171,
          172,
          173,
          174,
          175,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          189,
          190,
          191,
          192,
          193,
          194,
          196,
          197,
          198,
          199,
          201,
          203,
          205,
          206,
          207,
          208,
          211,
          212,
          213,
          214,
          215,
          216,
          218,
          220,
          221,
          222,
          223,
          224,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          235,
          239,
          241,
          244,
          248,
          249,
          250,
          252,
          253,
          257,
          258,
          259,
          261,
          262,
          263,
          264,
          265,
          267,
          268,
          269,
          270,
          271,
          273,
          274,
          278,
          283,
          284,
          286,
          287,
          290,
          294,
          295,
          296,
          297,
          301,
          306,
          307,
          308,
          309,
          312,
          313,
          316,
          317,
          318,
          322,
          323,
          324,
          332,
          343,
          347,
          348,
          350,
          352,
          355,
          358,
          365,
          369,
          372,
          376,
          377,
          378,
          387,
          389,
          390,
          393,
          395,
          404,
          424,
          425,
          438,
          470,
          474,
          480,
          483,
          508,
          530,
          626,
          675,
          727
         ],
         "y": [
          32,
          24,
          23,
          21,
          21,
          16,
          19,
          16,
          15,
          12,
          14,
          8,
          9,
          16,
          8,
          11,
          8,
          8,
          9,
          8,
          7,
          8,
          8,
          10,
          8,
          5,
          7,
          12,
          6,
          6,
          5,
          12,
          3,
          9,
          6,
          6,
          6,
          8,
          10,
          6,
          3,
          2,
          7,
          6,
          7,
          6,
          6,
          4,
          5,
          2,
          3,
          7,
          2,
          4,
          4,
          8,
          4,
          2,
          1,
          3,
          4,
          5,
          2,
          3,
          2,
          1,
          3,
          2,
          4,
          2,
          2,
          5,
          1,
          2,
          2,
          2,
          5,
          3,
          3,
          5,
          2,
          4,
          4,
          4,
          6,
          4,
          4,
          3,
          2,
          3,
          1,
          2,
          4,
          1,
          3,
          1,
          3,
          6,
          2,
          1,
          4,
          1,
          1,
          4,
          2,
          2,
          1,
          2,
          2,
          4,
          1,
          5,
          2,
          3,
          2,
          2,
          2,
          2,
          3,
          3,
          2,
          2,
          4,
          3,
          4,
          4,
          2,
          1,
          4,
          3,
          2,
          1,
          1,
          3,
          2,
          2,
          3,
          2,
          1,
          3,
          1,
          4,
          2,
          1,
          1,
          2,
          2,
          1,
          1,
          4,
          1,
          4,
          3,
          3,
          3,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          1,
          1,
          1,
          1,
          1,
          3,
          3,
          1,
          2,
          1,
          2,
          1,
          1,
          3,
          3,
          1,
          2,
          1,
          1,
          2,
          2,
          2,
          1,
          1,
          2,
          3,
          2,
          1,
          3,
          1,
          1,
          1,
          1,
          1,
          1,
          3,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          2,
          1,
          1,
          2,
          2,
          1,
          2,
          2,
          1,
          1,
          1,
          2,
          1,
          2,
          1,
          2,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "titlefont": {
         "color": "#4D5663"
        },
        "xaxis1": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": "",
         "titlefont": {
          "color": "#4D5663"
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis1": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": "",
         "titlefont": {
          "color": "#4D5663"
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div id=\"26f6755f-aeea-4661-8b4c-74180d7a3454\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"26f6755f-aeea-4661-8b4c-74180d7a3454\", [{\"type\": \"bar\", \"x\": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 161, 162, 163, 164, 165, 167, 169, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 201, 203, 205, 206, 207, 208, 211, 212, 213, 214, 215, 216, 218, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 235, 239, 241, 244, 248, 249, 250, 252, 253, 257, 258, 259, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 278, 283, 284, 286, 287, 290, 294, 295, 296, 297, 301, 306, 307, 308, 309, 312, 313, 316, 317, 318, 322, 323, 324, 332, 343, 347, 348, 350, 352, 355, 358, 365, 369, 372, 376, 377, 378, 387, 389, 390, 393, 395, 404, 424, 425, 438, 470, 474, 480, 483, 508, 530, 626, 675, 727], \"y\": [32, 24, 23, 21, 21, 16, 19, 16, 15, 12, 14, 8, 9, 16, 8, 11, 8, 8, 9, 8, 7, 8, 8, 10, 8, 5, 7, 12, 6, 6, 5, 12, 3, 9, 6, 6, 6, 8, 10, 6, 3, 2, 7, 6, 7, 6, 6, 4, 5, 2, 3, 7, 2, 4, 4, 8, 4, 2, 1, 3, 4, 5, 2, 3, 2, 1, 3, 2, 4, 2, 2, 5, 1, 2, 2, 2, 5, 3, 3, 5, 2, 4, 4, 4, 6, 4, 4, 3, 2, 3, 1, 2, 4, 1, 3, 1, 3, 6, 2, 1, 4, 1, 1, 4, 2, 2, 1, 2, 2, 4, 1, 5, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 4, 3, 4, 4, 2, 1, 4, 3, 2, 1, 1, 3, 2, 2, 3, 2, 1, 3, 1, 4, 2, 1, 1, 2, 2, 1, 1, 4, 1, 4, 3, 3, 3, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 2, 1, 1, 3, 3, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 3, 2, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"name\": \"None\", \"text\": \"\", \"marker\": {\"color\": \"rgba(255, 153, 51, 0.6)\", \"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"width\": 1}}, \"orientation\": \"v\"}], {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"yaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"gridcolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\", \"showgrid\": true, \"title\": \"\"}, \"xaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"gridcolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\", \"showgrid\": true, \"title\": \"\"}, \"titlefont\": {\"color\": \"#4D5663\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"26f6755f-aeea-4661-8b4c-74180d7a3454\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"26f6755f-aeea-4661-8b4c-74180d7a3454\", [{\"type\": \"bar\", \"x\": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 161, 162, 163, 164, 165, 167, 169, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 201, 203, 205, 206, 207, 208, 211, 212, 213, 214, 215, 216, 218, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 235, 239, 241, 244, 248, 249, 250, 252, 253, 257, 258, 259, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 278, 283, 284, 286, 287, 290, 294, 295, 296, 297, 301, 306, 307, 308, 309, 312, 313, 316, 317, 318, 322, 323, 324, 332, 343, 347, 348, 350, 352, 355, 358, 365, 369, 372, 376, 377, 378, 387, 389, 390, 393, 395, 404, 424, 425, 438, 470, 474, 480, 483, 508, 530, 626, 675, 727], \"y\": [32, 24, 23, 21, 21, 16, 19, 16, 15, 12, 14, 8, 9, 16, 8, 11, 8, 8, 9, 8, 7, 8, 8, 10, 8, 5, 7, 12, 6, 6, 5, 12, 3, 9, 6, 6, 6, 8, 10, 6, 3, 2, 7, 6, 7, 6, 6, 4, 5, 2, 3, 7, 2, 4, 4, 8, 4, 2, 1, 3, 4, 5, 2, 3, 2, 1, 3, 2, 4, 2, 2, 5, 1, 2, 2, 2, 5, 3, 3, 5, 2, 4, 4, 4, 6, 4, 4, 3, 2, 3, 1, 2, 4, 1, 3, 1, 3, 6, 2, 1, 4, 1, 1, 4, 2, 2, 1, 2, 2, 4, 1, 5, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 4, 3, 4, 4, 2, 1, 4, 3, 2, 1, 1, 3, 2, 2, 3, 2, 1, 3, 1, 4, 2, 1, 1, 2, 2, 1, 1, 4, 1, 4, 3, 3, 3, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 2, 1, 1, 3, 3, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 3, 2, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"name\": \"None\", \"text\": \"\", \"marker\": {\"color\": \"rgba(255, 153, 51, 0.6)\", \"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"width\": 1}}, \"orientation\": \"v\"}], {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"yaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"gridcolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\", \"showgrid\": true, \"title\": \"\"}, \"xaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"gridcolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\", \"showgrid\": true, \"title\": \"\"}, \"titlefont\": {\"color\": \"#4D5663\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = data_df.groupby('user_id').count()\n",
    "tmp = tmp.rename(columns={'film_id' : 'film_count'})\n",
    "tmp.groupby('film_count').size().iplot(kind='bar')\n",
    "#tmp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and populate matrix for Matrix-Factorization\n",
    "We observe our dataset has 1682 films rated by 943 users. That will be the size of our matrix. We also want to know about the sparsity of our matrix; so we'll calculate that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building UA Training Matrix\n",
      "Sparsity: 5.71%\n",
      "Building UA Testing Matrix\n",
      "Sparsity: 0.59%\n"
     ]
    }
   ],
   "source": [
    "def build_matrix(user_max, film_max, df, name=''):\n",
    "    print('Building {name} Matrix'.format(name=name))\n",
    "\n",
    "    matrix = np.zeros((user_max, film_max))\n",
    "    for row in df.itertuples():\n",
    "        matrix[row.user_id - 1, row.film_id - 1] = row.rating\n",
    "        \n",
    "    sparsity = float(len(matrix.nonzero()[0]))\n",
    "    sparsity /= (matrix.shape[0] * matrix.shape[1])\n",
    "    sparsity *= 100\n",
    "    print('Sparsity: {:4.2f}%'.format(sparsity))\n",
    "    return matrix\n",
    "\n",
    "training_matrix = build_matrix(users, films, data_df, name='UA Training')\n",
    "testing_matrix  = build_matrix(users, films, test_df, name='UA Testing')\n",
    "\n",
    "# Validate we have a disjoint training/testing datasets\n",
    "assert(np.all((training_matrix * testing_matrix) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://gist.github.com/EthanRosenthal/a0816d8fea4394baf732\n",
    "from numpy.linalg import solve\n",
    "\n",
    "class ExplicitMF():\n",
    "    def __init__(self, ratings, iterations=[10], n_factors=40, item_reg=0.0, user_reg=0.0, verbose=False):\n",
    "        \"\"\"\n",
    "        Train a matrix factorization model to predict all empty entries in a matrix.\n",
    "        The terminology assumes a ratings matrix which is ~ USER x ITEM\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        ratings : (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "        \n",
    "        n_factors : (int)\n",
    "            Number of latent factors (to assume) in factorization model\n",
    "        \n",
    "        item_reg : (float)\n",
    "            Regularization term for item latent factors\n",
    "        \n",
    "        user_reg : (float)\n",
    "            Regularization term for user latent factors\n",
    "        \n",
    "        verbose : (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.n_factors = n_factors\n",
    "        self.item_reg = item_reg\n",
    "        self.user_reg = user_reg\n",
    "        self.iterations = iterations\n",
    "        self._v = verbose\n",
    "\n",
    "\n",
    "    def als_step(self, latent_vectors, fixed_vecs, ratings, _lambda, type='user'):\n",
    "        \"\"\" One of two ALS steps. Solve for the latent vectors specified by type. \"\"\"\n",
    "\n",
    "        if type == 'user':\n",
    "            # Precompute\n",
    "            YTY = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(YTY.shape[0]) * _lambda\n",
    "            for u in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[u, :] = solve((YTY + lambdaI), ratings[u, :].dot(fixed_vecs))\n",
    "        \n",
    "        elif type == 'item':\n",
    "            # Precompute\n",
    "            XTX = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(XTX.shape[0]) * _lambda\n",
    "            for i in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[i, :] = solve((XTX + lambdaI), ratings[:, i].T.dot(fixed_vecs))\n",
    "\n",
    "        return latent_vectors\n",
    "\n",
    "    \n",
    "    \n",
    "    def train(self, n_iter = 10):\n",
    "        \"\"\" Train model for n_iter iterations from scratch.\"\"\"\n",
    "        # initialize latent vectors\n",
    "        self.user_vecs = np.random.random((self.n_users, self.n_factors))\n",
    "        self.item_vecs = np.random.random((self.n_items, self.n_factors))        \n",
    "        self.partial_train(n_iter)\n",
    "\n",
    "        \n",
    "    \n",
    "    def partial_train(self, n_iter):\n",
    "        \"\"\" Train model for n_iter iterations. Can be called multiple times for further training. \"\"\"\n",
    "        while (n_iter):\n",
    "            if (self._v): print('\\titerations left: {}'.format(n_iter))\n",
    "            self.user_vecs = self.als_step(self.user_vecs, self.item_vecs, self.ratings, self.user_reg, type='user')\n",
    "            self.item_vecs = self.als_step(self.item_vecs, self.user_vecs, self.ratings, self.item_reg, type='item')\n",
    "            n_iter = n_iter - 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict_all(self):\n",
    "        \"\"\" Predict ratings for every user and item. \"\"\"\n",
    "        predictions = np.zeros((self.user_vecs.shape[0], self.item_vecs.shape[0]))\n",
    "        for u in range(self.user_vecs.shape[0]):\n",
    "            for i in range(self.item_vecs.shape[0]):\n",
    "                predictions[u, i] = self.predict(u, i)\n",
    "                \n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, u, i):\n",
    "        \"\"\" Single user and item prediction. \"\"\"\n",
    "        return self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def calculate_learning_curve(self, test_matrix):\n",
    "        \"\"\"\n",
    "        Track MSE as a function of training iterations.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        test : (2D ndarray)\n",
    "            Testing dataset (assumed to be USER x ITEM).\n",
    "        \n",
    "        The function creates two new class attributes:\n",
    "        \n",
    "        train_mse : (list)\n",
    "            Training data MSE values for each value of iterations\n",
    "        test_mse : (list)\n",
    "            Test data MSE values for each value of iterations\n",
    "        \"\"\"\n",
    "\n",
    "        print (\"Calculate learning curve\")\n",
    "\n",
    "        self.iterations.sort()\n",
    "        self.train_mse = []\n",
    "        self.test_mse  = []\n",
    "        iter_diff = 0\n",
    "\n",
    "        for (i, n_iter) in enumerate(self.iterations):\n",
    "            if (self._v): print('Iteration: {}'.format(n_iter))\n",
    "            if i == 0:\n",
    "                #if self._v: print('i = 0; train({})'.format(n_iter - iter_diff))\n",
    "                self.train(n_iter - iter_diff)\n",
    "            else:\n",
    "                #if self._v: print('partial_train({})'.format(n_iter - iter_diff))\n",
    "                self.partial_train(n_iter - iter_diff)\n",
    "\n",
    "            predictions = self.predict_all()\n",
    "\n",
    "            self.train_mse += [get_mse(predictions, self.ratings)]\n",
    "            self.test_mse  += [get_mse(predictions, test_matrix)]\n",
    "            if (self._v):\n",
    "                print('Train mse: ' + str(self.train_mse[-1]))\n",
    "                print('Test mse:  ' + str(self.test_mse[-1]))\n",
    "            iter_diff = n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # calc MSE (true ratings - predicted)^2\n",
    "    pred   = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iter_array = [1, 2, 5, 10, 15, 25, 50, 75, 100]\n",
    "MF_ALS = ExplicitMF(ratings_matrix, n_factors=40, user_reg=0.0, item_reg=0.0, iterations=iter_array, verbose=True)\n",
    "MF_ALS.calculate_learning_curve(testing_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model):\n",
    "    # create our data traces (training MSE and testing MSE)\n",
    "    trace_training = go.Scatter(x=model.iterations, y=model.train_mse, name='training')\n",
    "    trace_testing  = go.Scatter(x=model.iterations, y=model.test_mse,  name='testing')\n",
    "    layout = dict(\n",
    "        title=\"MovieLens Learning Curve\", \n",
    "        xaxis=dict(title=\"Iterations\"),\n",
    "        yaxis=dict(title=\"Mean Squared Error\")\n",
    "    )\n",
    "\n",
    "    figure = dict(data=[trace_training, trace_testing], layout=layout)\n",
    "    py.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(MF_ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_ALS_10 = ExplicitMF(ratings_matrix, n_factors=10, user_reg=0.0, item_reg=0.0, iterations=iter_array)\n",
    "MF_ALS_25 = ExplicitMF(ratings_matrix, n_factors=25, user_reg=0.0, item_reg=0.0, iterations=iter_array)\n",
    "MF_ALS_50 = ExplicitMF(ratings_matrix, n_factors=50, user_reg=0.0, item_reg=0.0, iterations=iter_array)\n",
    "MF_ALS_75 = ExplicitMF(ratings_matrix, n_factors=75, user_reg=0.0, item_reg=0.0, iterations=iter_array)\n",
    "\n",
    "MF_ALS_10.calculate_learning_curve(testing_matrix)\n",
    "MF_ALS_25.calculate_learning_curve(testing_matrix)\n",
    "MF_ALS_50.calculate_learning_curve(testing_matrix)\n",
    "MF_ALS_75.calculate_learning_curve(testing_matrix)\n",
    "\n",
    "plot_learning_curve(MF_ALS_10)\n",
    "plot_learning_curve(MF_ALS_25)\n",
    "plot_learning_curve(MF_ALS_50)\n",
    "plot_learning_curve(MF_ALS_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MF_ALS_10 = ExplicitMF(ratings_matrix, n_factors=40, user_reg=0.0, item_reg=0.0, iterations=[12,14,32,42])\n",
    "MF_ALS_10.calculate_learning_curve(testing_matrix)\n",
    "plot_learning_curve(MF_ALS_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors: 3\n",
      "Regularization: 0.1\n",
      "Calculate learning curve\n",
      "New optimal hyperparameters\n",
      "model        <__main__.ExplicitMF object at 0x7fa7b1c277f0>\n",
      "n_factors                                                 3\n",
      "n_iter                                                  100\n",
      "reg                                                     0.1\n",
      "test_mse                                            9.20928\n",
      "train_mse                                           6.63216\n",
      "dtype: object\n",
      "Regularization: 0.3\n",
      "Calculate learning curve\n",
      "Regularization: 1.0\n",
      "Calculate learning curve\n",
      "Regularization: 1.5\n",
      "Calculate learning curve\n",
      "Regularization: 10.0\n",
      "Calculate learning curve\n",
      "Regularization: 100.0\n",
      "Calculate learning curve\n",
      "Factors: 5\n",
      "Regularization: 0.1\n",
      "Calculate learning curve\n",
      "New optimal hyperparameters\n",
      "model        <__main__.ExplicitMF object at 0x7fa7b1c276d8>\n",
      "n_factors                                                 5\n",
      "n_iter                                                  100\n",
      "reg                                                     0.1\n",
      "test_mse                                            8.71804\n",
      "train_mse                                           6.13276\n",
      "dtype: object\n",
      "Regularization: 0.3\n",
      "Calculate learning curve\n",
      "Regularization: 1.0\n",
      "Calculate learning curve\n",
      "New optimal hyperparameters\n",
      "model        <__main__.ExplicitMF object at 0x7fa7b1c27828>\n",
      "n_factors                                                 5\n",
      "n_iter                                                   65\n",
      "reg                                                       1\n",
      "test_mse                                            8.62636\n",
      "train_mse                                           6.15841\n",
      "dtype: object\n",
      "Regularization: 1.5\n",
      "Calculate learning curve\n",
      "Regularization: 10.0\n",
      "Calculate learning curve\n",
      "Regularization: 100.0\n",
      "Calculate learning curve\n",
      "Factors: 8\n",
      "Regularization: 0.1\n",
      "Calculate learning curve\n"
     ]
    }
   ],
   "source": [
    "latent_factors = [3, 5, 8, 10, 15, 20, 40, 80]\n",
    "regularizations = [0.1, 0.3, 1., 1.5, 10., 100.]\n",
    "snapshot_errors = [1, 2, 5, 10, 20, 35, 50, 65, 75, 85, 100]\n",
    "\n",
    "snapshot_errors.sort()\n",
    "regularizations.sort()\n",
    "\n",
    "best_params = {}\n",
    "best_params['n_factors'] = latent_factors[0]\n",
    "best_params['reg'] = regularizations[0]\n",
    "best_params['n_iter'] = 0\n",
    "best_params['train_mse'] = np.inf\n",
    "best_params['test_mse'] = np.inf\n",
    "best_params['model'] = None\n",
    "\n",
    "for fact in latent_factors:\n",
    "    print('Factors: {}'.format(fact))\n",
    "    for reg in regularizations:\n",
    "        print('Regularization: {}'.format(reg))\n",
    "        \n",
    "        MF_ALS = ExplicitMF(ratings_matrix, n_factors=fact, user_reg=reg, item_reg=reg, iterations=snapshot_errors)\n",
    "        MF_ALS.calculate_learning_curve(testing_matrix)\n",
    "\n",
    "        min_idx = np.argmin(MF_ALS.test_mse)\n",
    "        if MF_ALS.test_mse[min_idx] < best_params['test_mse']:\n",
    "            best_params['n_factors'] = fact\n",
    "            best_params['reg'] = reg\n",
    "            best_params['n_iter'] = snapshot_errors[min_idx]\n",
    "            best_params['train_mse'] = MF_ALS.train_mse[min_idx]\n",
    "            best_params['test_mse'] = MF_ALS.test_mse[min_idx]\n",
    "            best_params['model'] = MF_ALS\n",
    "            print('New optimal hyperparameters')\n",
    "            print(pd.Series(best_params))\n",
    "\n",
    "print('Optimal hyperparameters')\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_factors': 20, 'reg': 0.1, 'n_iter': 100, 'train_mse': 4.765966673253817, 'test_mse': 7.995238974340978, 'model': <__main__.ExplicitMF object at 0x7fa7b20c67b8>}\n"
     ]
    }
   ],
   "source": [
    "print (best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "training",
         "type": "scatter",
         "x": [
          1,
          2,
          5,
          10,
          25,
          50,
          100
         ],
         "y": [
          6.457284799133258,
          5.081943269912411,
          4.82362315065242,
          4.795822247398843,
          4.780048569854972,
          4.772538901652775,
          4.7664527811561985
         ]
        },
        {
         "name": "testing",
         "type": "scatter",
         "x": [
          1,
          2,
          5,
          10,
          25,
          50,
          100
         ],
         "y": [
          9.969255221234068,
          8.371411321651582,
          8.06414411619196,
          8.027380010095012,
          8.008912355874488,
          7.998273686518422,
          7.9950156559162044
         ]
        }
       ],
       "layout": {
        "title": "MovieLens Learning Curve",
        "xaxis": {
         "title": "Iterations"
        },
        "yaxis": {
         "title": "Mean Squared Error"
        }
       }
      },
      "text/html": [
       "<div id=\"bad37bec-8697-466d-96b0-7c4e361a1cfb\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bad37bec-8697-466d-96b0-7c4e361a1cfb\", [{\"type\": \"scatter\", \"x\": [1, 2, 5, 10, 25, 50, 100], \"y\": [6.457284799133258, 5.081943269912411, 4.82362315065242, 4.795822247398843, 4.780048569854972, 4.772538901652775, 4.7664527811561985], \"name\": \"training\"}, {\"type\": \"scatter\", \"x\": [1, 2, 5, 10, 25, 50, 100], \"y\": [9.969255221234068, 8.371411321651582, 8.06414411619196, 8.027380010095012, 8.008912355874488, 7.998273686518422, 7.9950156559162044], \"name\": \"testing\"}], {\"title\": \"MovieLens Learning Curve\", \"xaxis\": {\"title\": \"Iterations\"}, \"yaxis\": {\"title\": \"Mean Squared Error\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"bad37bec-8697-466d-96b0-7c4e361a1cfb\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bad37bec-8697-466d-96b0-7c4e361a1cfb\", [{\"type\": \"scatter\", \"x\": [1, 2, 5, 10, 25, 50, 100], \"y\": [6.457284799133258, 5.081943269912411, 4.82362315065242, 4.795822247398843, 4.780048569854972, 4.772538901652775, 4.7664527811561985], \"name\": \"training\"}, {\"type\": \"scatter\", \"x\": [1, 2, 5, 10, 25, 50, 100], \"y\": [9.969255221234068, 8.371411321651582, 8.06414411619196, 8.027380010095012, 8.008912355874488, 7.998273686518422, 7.9950156559162044], \"name\": \"testing\"}], {\"title\": \"MovieLens Learning Curve\", \"xaxis\": {\"title\": \"Iterations\"}, \"yaxis\": {\"title\": \"Mean Squared Error\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(best_params['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_df.set_index('film_id')\n",
    "film_df[film_df['film_id'] == 2]['title']\n",
    "\n",
    "def get_film(idx):\n",
    "    return film_df[film_df['film_id'] == idx]\n",
    "\n",
    "def get_film_title(idx):\n",
    "    film = get_film(idx)\n",
    "    name = film['title']\n",
    "    return name.values[0][0:-7]\n",
    "\n",
    "print (get_film(1581))\n",
    "print (get_film(1652))\n",
    "\n",
    "print (get_film_title(55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1672 1357 1356 ...    1 1652 1581]\n",
      "[1581 1652    1 ... 1356 1357 1672]\n",
      "film: Toy Story\n",
      "1581 Woman in Question, The\n",
      "1652 Temptress Moon (Feng Yue)\n",
      "1 Toy Story\n",
      "232 Young Guns\n",
      "549 Rob Roy\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/17627219/whats-the-fastest-way-in-python-to-calculate-cosine-similarity-given-sparse-mat\n",
    "\n",
    "def cosine_similarity(model):\n",
    "    dense = model.item_vecs.dot(model.item_vecs.T)  # calculate the dense (fill in) matrix\n",
    "    norms = np.array([np.sqrt(np.diagonal(dense))]) # calculate the normalization vectors\n",
    "    return dense / norms / norms.T\n",
    "\n",
    "als_sim = cosine_similarity(best_params['model'])\n",
    "\n",
    "def display_top_k_movies(model, film_id, k=5):\n",
    "    film_similarity = np.argsort(model[film_id,:])\n",
    "    print (film_similarity)\n",
    "    sort_similarity = film_similarity[::-1]\n",
    "    print (sort_similarity)\n",
    "    topx_similarity = sort_similarity[0:k]\n",
    "\n",
    "    print ('film:', get_film_title(film_id))\n",
    "    for film in topx_similarity:\n",
    "        print (film, get_film_title(film))\n",
    "\n",
    "display_top_k_movies(als_sim, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ExplicitMF' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-475f03ff3609>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'ExplicitMF' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
