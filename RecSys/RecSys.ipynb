{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install cufflinks==0.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os\n",
    "import re, json\n",
    "import pickle, gzip\n",
    "import itertools\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "import boto3\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "import cufflinks as cf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import  Image\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# plotly + cufflinks work offline\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'slalom-ml'\n",
    "prefix = 'tmp/sagemaker/demo/recsys/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Movie Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "%cd ml-100k\n",
    "#!shuf ua.base -o ua.base.shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!cat README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Data and Exploratory Data Analysis\n",
    "\n",
    "We observe the ratings are not in a matrix format, but are in a _long and skinny_ format.  We'll need to build the matrix ourselves.\n",
    "\n",
    "We also observe there is a user dataset in **u.user**, providing some infor about gender, occupation, and zipcode. And information about the movie itself: title, release date, URL, and category in the **u.item** file.  Lastly, I think about how I've rated movies; I'm curious if there is any skew to the ratings themselves.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_column_names = ['user_id', 'age', 'gender', 'occupation', 'zip code']\n",
    "film_column_names = ['film_id', 'title', 'release date', 'home release date', 'URL', 'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Noir','Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "data_column_names = ['user_id', 'film_id', 'rating', 'timestamp']\n",
    "user_df = pd.read_csv('u.user', sep='|', names=user_column_names)\n",
    "film_df = pd.read_csv('u.item', sep='|', names=film_column_names, encoding = \"ISO-8859-1\")\n",
    "\n",
    "ua_data = pd.read_csv('ua.base', sep='\\t', names=data_column_names).drop(['timestamp'], axis=1)\n",
    "ua_test = pd.read_csv('ua.test', sep='\\t', names=data_column_names).drop(['timestamp'], axis=1)\n",
    "\n",
    "data_df = ua_data\n",
    "test_df = ua_test\n",
    "print('\\nDESCRIPTION of Ratings data\\n')\n",
    "print(data_df.describe())\n",
    "\n",
    "print('\\n\\nSAMPLE of UA Training (ratings)  data\\n')\n",
    "print(data_df.sample(n=5))\n",
    "\n",
    "print('\\n\\nSAMPLE of UA Testing (ratings) data\\n')\n",
    "print(test_df.sample(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data_df.user_id.max()\n",
    "films = data_df.film_id.max()\n",
    "\n",
    "data = [\n",
    "    go.Bar(x=['users'],  y=[users], name=\"Users\"),\n",
    "    go.Bar(x=['films'],  y=[films], name=\"Films\")\n",
    "]\n",
    "layout = dict(yaxis=dict(title='Count') )\n",
    "figure = dict(data=data, layout=layout)\n",
    "py.iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "Is there a lot of skew in our data?  What does the rating distribution look like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.groupby('rating').count()['film_id'].iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "rgba(255, 153, 51, 0.6)",
          "line": {
           "color": "rgba(255, 153, 51, 1.0)",
           "width": 1
          }
         },
         "name": "None",
         "orientation": "v",
         "text": "",
         "type": "bar",
         "x": [
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          79,
          80,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          155,
          156,
          157,
          158,
          161,
          162,
          163,
          164,
          165,
          167,
          169,
          171,
          172,
          173,
          174,
          175,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          189,
          190,
          191,
          192,
          193,
          194,
          196,
          197,
          198,
          199,
          201,
          203,
          205,
          206,
          207,
          208,
          211,
          212,
          213,
          214,
          215,
          216,
          218,
          220,
          221,
          222,
          223,
          224,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          235,
          239,
          241,
          244,
          248,
          249,
          250,
          252,
          253,
          257,
          258,
          259,
          261,
          262,
          263,
          264,
          265,
          267,
          268,
          269,
          270,
          271,
          273,
          274,
          278,
          283,
          284,
          286,
          287,
          290,
          294,
          295,
          296,
          297,
          301,
          306,
          307,
          308,
          309,
          312,
          313,
          316,
          317,
          318,
          322,
          323,
          324,
          332,
          343,
          347,
          348,
          350,
          352,
          355,
          358,
          365,
          369,
          372,
          376,
          377,
          378,
          387,
          389,
          390,
          393,
          395,
          404,
          424,
          425,
          438,
          470,
          474,
          480,
          483,
          508,
          530,
          626,
          675,
          727
         ],
         "y": [
          32,
          24,
          23,
          21,
          21,
          16,
          19,
          16,
          15,
          12,
          14,
          8,
          9,
          16,
          8,
          11,
          8,
          8,
          9,
          8,
          7,
          8,
          8,
          10,
          8,
          5,
          7,
          12,
          6,
          6,
          5,
          12,
          3,
          9,
          6,
          6,
          6,
          8,
          10,
          6,
          3,
          2,
          7,
          6,
          7,
          6,
          6,
          4,
          5,
          2,
          3,
          7,
          2,
          4,
          4,
          8,
          4,
          2,
          1,
          3,
          4,
          5,
          2,
          3,
          2,
          1,
          3,
          2,
          4,
          2,
          2,
          5,
          1,
          2,
          2,
          2,
          5,
          3,
          3,
          5,
          2,
          4,
          4,
          4,
          6,
          4,
          4,
          3,
          2,
          3,
          1,
          2,
          4,
          1,
          3,
          1,
          3,
          6,
          2,
          1,
          4,
          1,
          1,
          4,
          2,
          2,
          1,
          2,
          2,
          4,
          1,
          5,
          2,
          3,
          2,
          2,
          2,
          2,
          3,
          3,
          2,
          2,
          4,
          3,
          4,
          4,
          2,
          1,
          4,
          3,
          2,
          1,
          1,
          3,
          2,
          2,
          3,
          2,
          1,
          3,
          1,
          4,
          2,
          1,
          1,
          2,
          2,
          1,
          1,
          4,
          1,
          4,
          3,
          3,
          3,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          1,
          1,
          1,
          1,
          1,
          3,
          3,
          1,
          2,
          1,
          2,
          1,
          1,
          3,
          3,
          1,
          2,
          1,
          1,
          2,
          2,
          2,
          1,
          1,
          2,
          3,
          2,
          1,
          3,
          1,
          1,
          1,
          1,
          1,
          1,
          3,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          2,
          1,
          1,
          2,
          2,
          1,
          2,
          2,
          1,
          1,
          1,
          2,
          1,
          2,
          1,
          2,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "titlefont": {
         "color": "#4D5663"
        },
        "xaxis1": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": "",
         "titlefont": {
          "color": "#4D5663"
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis1": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": "",
         "titlefont": {
          "color": "#4D5663"
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div id=\"26f6755f-aeea-4661-8b4c-74180d7a3454\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"26f6755f-aeea-4661-8b4c-74180d7a3454\", [{\"type\": \"bar\", \"x\": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 161, 162, 163, 164, 165, 167, 169, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 201, 203, 205, 206, 207, 208, 211, 212, 213, 214, 215, 216, 218, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 235, 239, 241, 244, 248, 249, 250, 252, 253, 257, 258, 259, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 278, 283, 284, 286, 287, 290, 294, 295, 296, 297, 301, 306, 307, 308, 309, 312, 313, 316, 317, 318, 322, 323, 324, 332, 343, 347, 348, 350, 352, 355, 358, 365, 369, 372, 376, 377, 378, 387, 389, 390, 393, 395, 404, 424, 425, 438, 470, 474, 480, 483, 508, 530, 626, 675, 727], \"y\": [32, 24, 23, 21, 21, 16, 19, 16, 15, 12, 14, 8, 9, 16, 8, 11, 8, 8, 9, 8, 7, 8, 8, 10, 8, 5, 7, 12, 6, 6, 5, 12, 3, 9, 6, 6, 6, 8, 10, 6, 3, 2, 7, 6, 7, 6, 6, 4, 5, 2, 3, 7, 2, 4, 4, 8, 4, 2, 1, 3, 4, 5, 2, 3, 2, 1, 3, 2, 4, 2, 2, 5, 1, 2, 2, 2, 5, 3, 3, 5, 2, 4, 4, 4, 6, 4, 4, 3, 2, 3, 1, 2, 4, 1, 3, 1, 3, 6, 2, 1, 4, 1, 1, 4, 2, 2, 1, 2, 2, 4, 1, 5, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 4, 3, 4, 4, 2, 1, 4, 3, 2, 1, 1, 3, 2, 2, 3, 2, 1, 3, 1, 4, 2, 1, 1, 2, 2, 1, 1, 4, 1, 4, 3, 3, 3, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 2, 1, 1, 3, 3, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 3, 2, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"name\": \"None\", \"text\": \"\", \"marker\": {\"color\": \"rgba(255, 153, 51, 0.6)\", \"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"width\": 1}}, \"orientation\": \"v\"}], {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"yaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"gridcolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\", \"showgrid\": true, \"title\": \"\"}, \"xaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"gridcolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\", \"showgrid\": true, \"title\": \"\"}, \"titlefont\": {\"color\": \"#4D5663\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"26f6755f-aeea-4661-8b4c-74180d7a3454\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"26f6755f-aeea-4661-8b4c-74180d7a3454\", [{\"type\": \"bar\", \"x\": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 161, 162, 163, 164, 165, 167, 169, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 201, 203, 205, 206, 207, 208, 211, 212, 213, 214, 215, 216, 218, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 235, 239, 241, 244, 248, 249, 250, 252, 253, 257, 258, 259, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 278, 283, 284, 286, 287, 290, 294, 295, 296, 297, 301, 306, 307, 308, 309, 312, 313, 316, 317, 318, 322, 323, 324, 332, 343, 347, 348, 350, 352, 355, 358, 365, 369, 372, 376, 377, 378, 387, 389, 390, 393, 395, 404, 424, 425, 438, 470, 474, 480, 483, 508, 530, 626, 675, 727], \"y\": [32, 24, 23, 21, 21, 16, 19, 16, 15, 12, 14, 8, 9, 16, 8, 11, 8, 8, 9, 8, 7, 8, 8, 10, 8, 5, 7, 12, 6, 6, 5, 12, 3, 9, 6, 6, 6, 8, 10, 6, 3, 2, 7, 6, 7, 6, 6, 4, 5, 2, 3, 7, 2, 4, 4, 8, 4, 2, 1, 3, 4, 5, 2, 3, 2, 1, 3, 2, 4, 2, 2, 5, 1, 2, 2, 2, 5, 3, 3, 5, 2, 4, 4, 4, 6, 4, 4, 3, 2, 3, 1, 2, 4, 1, 3, 1, 3, 6, 2, 1, 4, 1, 1, 4, 2, 2, 1, 2, 2, 4, 1, 5, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 4, 3, 4, 4, 2, 1, 4, 3, 2, 1, 1, 3, 2, 2, 3, 2, 1, 3, 1, 4, 2, 1, 1, 2, 2, 1, 1, 4, 1, 4, 3, 3, 3, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 2, 1, 1, 3, 3, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 3, 2, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"name\": \"None\", \"text\": \"\", \"marker\": {\"color\": \"rgba(255, 153, 51, 0.6)\", \"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"width\": 1}}, \"orientation\": \"v\"}], {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"yaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"gridcolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\", \"showgrid\": true, \"title\": \"\"}, \"xaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"gridcolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}, \"zerolinecolor\": \"#E1E5ED\", \"showgrid\": true, \"title\": \"\"}, \"titlefont\": {\"color\": \"#4D5663\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = data_df.groupby('user_id').count()\n",
    "tmp = tmp.rename(columns={'film_id' : 'film_count'})\n",
    "tmp.groupby('film_count').size().iplot(kind='bar')\n",
    "#tmp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and populate matrix for Matrix-Factorization\n",
    "We observe our dataset has 1682 films rated by 943 users. That will be the size of our matrix. We also want to know about the sparsity of our matrix; so we'll calculate that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building UA Training Matrix\n",
      "Sparsity: 5.71%\n",
      "Building UA Testing Matrix\n",
      "Sparsity: 0.59%\n"
     ]
    }
   ],
   "source": [
    "def build_matrix(user_max, film_max, df, name=''):\n",
    "    print('Building {name} Matrix'.format(name=name))\n",
    "\n",
    "    matrix = np.zeros((user_max, film_max))\n",
    "    for row in df.itertuples():\n",
    "        matrix[row.user_id - 1, row.film_id - 1] = row.rating\n",
    "        \n",
    "    sparsity = float(len(matrix.nonzero()[0]))\n",
    "    sparsity /= (matrix.shape[0] * matrix.shape[1])\n",
    "    sparsity *= 100\n",
    "    print('Sparsity: {:4.2f}%'.format(sparsity))\n",
    "    return matrix\n",
    "\n",
    "training_matrix = build_matrix(users, films, data_df, name='UA Training')\n",
    "testing_matrix  = build_matrix(users, films, test_df, name='UA Testing')\n",
    "\n",
    "# Validate we have a disjoint training/testing datasets\n",
    "assert(np.all((training_matrix * testing_matrix) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://gist.github.com/EthanRosenthal/a0816d8fea4394baf732\n",
    "from numpy.linalg import solve\n",
    "\n",
    "class ExplicitMF():\n",
    "    def __init__(self, ratings, iterations=[10], n_factors=40, item_reg=0.0, user_reg=0.0, verbose=False):\n",
    "        \"\"\"\n",
    "        Train a matrix factorization model to predict all empty entries in a matrix.\n",
    "        The terminology assumes a ratings matrix which is ~ USER x ITEM\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        ratings : (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "        \n",
    "        n_factors : (int)\n",
    "            Number of latent factors (to assume) in factorization model\n",
    "        \n",
    "        item_reg : (float)\n",
    "            Regularization term for item latent factors\n",
    "        \n",
    "        user_reg : (float)\n",
    "            Regularization term for user latent factors\n",
    "        \n",
    "        verbose : (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.n_factors = n_factors\n",
    "        self.item_reg = item_reg\n",
    "        self.user_reg = user_reg\n",
    "        self.iterations = iterations\n",
    "        self._v = verbose\n",
    "\n",
    "\n",
    "    def als_step(self, latent_vectors, fixed_vecs, ratings, _lambda, type='user'):\n",
    "        \"\"\" One of two ALS steps. Solve for the latent vectors specified by type. \"\"\"\n",
    "\n",
    "        if type == 'user':\n",
    "            # Precompute\n",
    "            YTY = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(YTY.shape[0]) * _lambda\n",
    "            for u in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[u, :] = solve((YTY + lambdaI), ratings[u, :].dot(fixed_vecs))\n",
    "        \n",
    "        elif type == 'item':\n",
    "            # Precompute\n",
    "            XTX = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(XTX.shape[0]) * _lambda\n",
    "            for i in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[i, :] = solve((XTX + lambdaI), ratings[:, i].T.dot(fixed_vecs))\n",
    "\n",
    "        return latent_vectors\n",
    "\n",
    "    \n",
    "    \n",
    "    def train(self, n_iter = 10):\n",
    "        \"\"\" Train model for n_iter iterations from scratch.\"\"\"\n",
    "        # initialize latent vectors\n",
    "        self.user_vecs = np.random.random((self.n_users, self.n_factors))\n",
    "        self.item_vecs = np.random.random((self.n_items, self.n_factors))        \n",
    "        self.partial_train(n_iter)\n",
    "\n",
    "        \n",
    "    \n",
    "    def partial_train(self, n_iter):\n",
    "        \"\"\" Train model for n_iter iterations. Can be called multiple times for further training. \"\"\"\n",
    "        while (n_iter):\n",
    "            if (self._v): print('\\titerations left: {}'.format(n_iter))\n",
    "            self.user_vecs = self.als_step(self.user_vecs, self.item_vecs, self.ratings, self.user_reg, type='user')\n",
    "            self.item_vecs = self.als_step(self.item_vecs, self.user_vecs, self.ratings, self.item_reg, type='item')\n",
    "            n_iter = n_iter - 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict_all(self):\n",
    "        \"\"\" Predict ratings for every user and item. \"\"\"\n",
    "        predictions = np.zeros((self.user_vecs.shape[0], self.item_vecs.shape[0]))\n",
    "        for u in range(self.user_vecs.shape[0]):\n",
    "            for i in range(self.item_vecs.shape[0]):\n",
    "                predictions[u, i] = self.predict(u, i)\n",
    "                \n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, u, i):\n",
    "        \"\"\" Single user and item prediction. \"\"\"\n",
    "        return self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def calculate_learning_curve(self, test_matrix):\n",
    "        \"\"\"\n",
    "        Track MSE as a function of training iterations.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        test : (2D ndarray)\n",
    "            Testing dataset (assumed to be USER x ITEM).\n",
    "        \n",
    "        The function creates two new class attributes:\n",
    "        \n",
    "        train_mse : (list)\n",
    "            Training data MSE values for each value of iterations\n",
    "        test_mse : (list)\n",
    "            Test data MSE values for each value of iterations\n",
    "        \"\"\"\n",
    "\n",
    "        print (\"Calculate learning curve\")\n",
    "\n",
    "        self.iterations.sort()\n",
    "        self.train_mse = []\n",
    "        self.test_mse  = []\n",
    "        iter_diff = 0\n",
    "\n",
    "        for (i, n_iter) in enumerate(self.iterations):\n",
    "            print ('{}, {}'.format(i, n_iter))\n",
    "            if self._v:\n",
    "                print('Iteration: {}'.format(n_iter))\n",
    "            if i == 0:\n",
    "                print('i = 0; train({})'.format(n_iter - iter_diff))\n",
    "                self.train(n_iter - iter_diff)\n",
    "            else:\n",
    "                print('partial_train({})'.format(n_iter - iter_diff))\n",
    "                self.partial_train(n_iter - iter_diff)\n",
    "\n",
    "            predictions = self.predict_all()\n",
    "\n",
    "            self.train_mse += [get_mse(predictions, self.ratings)]\n",
    "            self.test_mse  += [get_mse(predictions, test_matrix)]\n",
    "            if (self._v):\n",
    "                print('Train mse: ' + str(self.train_mse[-1]))\n",
    "                print('Test mse:  ' + str(self.test_mse[-1]))\n",
    "            iter_diff = n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # calc MSE (true ratings - predicted)^2\n",
    "    pred   = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iter_array = [1, 2, 5, 10, 15, 25, 50, 75, 100]\n",
    "MF_ALS = ExplicitMF(ratings_matrix, n_factors=40, user_reg=0.0, item_reg=0.0, iterations=iter_array, verbose=True)\n",
    "MF_ALS.calculate_learning_curve(testing_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model):\n",
    "    # create our data traces (training MSE and testing MSE)\n",
    "    trace_training = go.Scatter(x=model.iterations, y=model.train_mse, name='training')\n",
    "    trace_testing  = go.Scatter(x=model.iterations, y=model.test_mse,  name='testing')\n",
    "    layout = dict(\n",
    "        title=\"MovieLens Learning Curve\", \n",
    "        xaxis=dict(title=\"Iterations\"),\n",
    "        yaxis=dict(title=\"Mean Squared Error\")\n",
    "    )\n",
    "\n",
    "    figure = dict(data=[trace_training, trace_testing], layout=layout)\n",
    "    py.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(MF_ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate learning curve\n",
      "0, 1\n",
      "i = 0; train(1)\n",
      "1, 2\n",
      "partial_train(1)\n",
      "2, 5\n",
      "partial_train(3)\n",
      "3, 10\n",
      "partial_train(5)\n",
      "4, 15\n",
      "partial_train(5)\n",
      "5, 25\n",
      "partial_train(10)\n",
      "6, 50\n",
      "partial_train(25)\n",
      "7, 75\n",
      "partial_train(25)\n",
      "8, 100\n",
      "partial_train(25)\n",
      "Calculate learning curve\n",
      "0, 1\n",
      "i = 0; train(1)\n",
      "1, 2\n",
      "partial_train(1)\n",
      "2, 5\n",
      "partial_train(3)\n",
      "3, 10\n",
      "partial_train(5)\n",
      "4, 15\n",
      "partial_train(5)\n",
      "5, 25\n",
      "partial_train(10)\n",
      "6, 50\n",
      "partial_train(25)\n"
     ]
    }
   ],
   "source": [
    "MF_ALS_10 = ExplicitMF(ratings_matrix, n_factors=10, user_reg=0.0, item_reg=0.0, iterations=iter_array)\n",
    "MF_ALS_25 = ExplicitMF(ratings_matrix, n_factors=25, user_reg=0.0, item_reg=0.0, iterations=iter_array)\n",
    "MF_ALS_50 = ExplicitMF(ratings_matrix, n_factors=50, user_reg=0.0, item_reg=0.0, iterations=iter_array)\n",
    "MF_ALS_75 = ExplicitMF(ratings_matrix, n_factors=75, user_reg=0.0, item_reg=0.0, iterations=iter_array)\n",
    "\n",
    "MF_ALS_10.calculate_learning_curve(testing_matrix)\n",
    "MF_ALS_25.calculate_learning_curve(testing_matrix)\n",
    "MF_ALS_50.calculate_learning_curve(testing_matrix)\n",
    "MF_ALS_75.calculate_learning_curve(testing_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ExplicitMF' object has no attribute 'train_mse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-f8dc7b346bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMF_ALS_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-146-2f8cbdabe318>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# create our data traces (training MSE and testing MSE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrace_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrace_testing\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     layout = dict(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ExplicitMF' object has no attribute 'train_mse'"
     ]
    }
   ],
   "source": [
    "plot_learning_curve(MF_ALS_10)\n",
    "plot_learning_curve(MF_ALS_25)\n",
    "plot_learning_curve(MF_ALS_50)\n",
    "plot_learning_curve(MF_ALS_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
